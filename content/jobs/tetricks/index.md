---
date: '2023-06-01'
title: 'AI Engineer'
company: 'Tetricks'
location: remote
range: 'Jun 2023 - Jun 2024'
url: ''
---
<!-- uptime. Serving the model using Ollama on a virtual machine, accessible via Flask API on Cloud Run.
- Architected and deployed production-grade ML pipelines for request classification on GCP, achieving 47%
reduction in operational costs through automated workflow optimization and efficient resource utilization
- Implemented LLM optimization techniques including distillation and quantization, delivering 3X faster
inference times while maintaining model performance
- Engineered an intelligent email processing system using LangChain and custom LLMs, resulting in 60%
improvement in request processing accuracy aginst the baseline based on regex -->
- Architected and deployed production-grade ML pipelines for request classification on GCP, achieving 47%
reduction in operational costs through automated workflow optimization and efficient resource utilization
- Designed and implemented a RAG-based chat application processing guest inquiries, achieving 50%
improvement in customer satisfaction and optimizing deployment through GCP services (Cloud Run)
- Implemented advanced LLM optimization techniques including fine-tuning and quantization, delivering 3X
faster inference times while maintaining model accuracy
- Engineered an intelligent email processing system using LangChain and custom LLMs, resulting in 60%
improvement in request processing accuracy
- Developed a Vision LLM pipeline for hotel room categorization with 99.9% uptime, achieving 40%
efficiency gain through automated feature extraction and classification
- Developed and deployed in-house solution for request classification, cutting costs by 47%.
- Optimized, fine-tuned, Quantized Language Models for Enhanced Performance, inference by up to 3X.
- Built an email parser API for guest request processing, automating data extraction from emails and reducing processing time by 60%.
- Created a RAG chat-app for quick and accurate resolution of guest inquiries, reducing response time by 50%.
- Employed vision LLM for automated hotel room and feature categorization, leading to a 40% increase in efficiency.


<!-- ---
date: '2024-06-01'
title: 'AI Engineer'
company: 'Tetricks'
location: remote
range: 'Jan 2024 - Jun 2024'
url: ''
---

- Architected and deployed production-grade ML pipelines for request classification on GCP, achieving 47%
reduction in operational costs through automated workflow optimization and efficient resource utilization
- Implemented LLM optimization techniques including distillation and quantization, delivering 3X faster
inference times while maintaining model performance
- Engineered an intelligent email processing system using LangChain and custom LLMs, resulting in 60%
improvement in request processing accuracy aginst the baseline based on regex -->